{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SOUMEN MONDAL\\AppData\\Local\\Temp\\ipykernel_21380\\31335101.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  main=pd.read_csv(\"weatherHistory (1).csv\",engine=\"python\",error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96453, 12)\n"
     ]
    }
   ],
   "source": [
    "main=pd.read_csv(\"weatherHistory (1).csv\",engine=\"python\",error_bad_lines=False)\n",
    "print(main.shape)\n",
    "data=main.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95936, 8)\n"
     ]
    }
   ],
   "source": [
    "data =data.dropna()\n",
    "data.drop([\"Formatted Date\",\"Daily Summary\",\"Summary\",\"Loud Cover\"],axis=1,inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SOUMEN MONDAL\\AppData\\Local\\Temp\\ipykernel_21380\\2536031948.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"Precip Type\"][data[\"Precip Type\"]==\"rain\"]=1\n",
      "C:\\Users\\SOUMEN MONDAL\\AppData\\Local\\Temp\\ipykernel_21380\\2536031948.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"Precip Type\"][data[\"Precip Type\"]==\"snow\"]=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Precip Type\"][data[\"Precip Type\"]==\"rain\"]=1\n",
    "data[\"Precip Type\"][data[\"Precip Type\"]==\"snow\"]=0\n",
    "data[\"Precip Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precip Type  Temperature (C)  Apparent Temperature (C)  Humidity  \\\n",
      "0           1         9.472222                  7.388889      0.89   \n",
      "1           1         9.355556                  7.227778      0.86   \n",
      "2           1         9.377778                  9.377778      0.89   \n",
      "3           1         8.288889                  5.944444      0.83   \n",
      "4           1         8.755556                  6.977778      0.83   \n",
      "\n",
      "   Wind Speed (km/h)  Wind Bearing (degrees)  Visibility (km)  \\\n",
      "0            14.1197                   251.0          15.8263   \n",
      "1            14.2646                   259.0          15.8263   \n",
      "2             3.9284                   204.0          14.9569   \n",
      "3            14.1036                   269.0          15.8263   \n",
      "4            11.0446                   259.0          15.8263   \n",
      "\n",
      "   Pressure (millibars)  \n",
      "0               1015.13  \n",
      "1               1015.63  \n",
      "2               1015.94  \n",
      "3               1016.41  \n",
      "4               1016.51  \n",
      "   Temperature (C)  Apparent Temperature (C)  Humidity  Wind Speed (km/h)  \\\n",
      "0         9.472222                  7.388889      0.89            14.1197   \n",
      "1         9.355556                  7.227778      0.86            14.2646   \n",
      "2         9.377778                  9.377778      0.89             3.9284   \n",
      "3         8.288889                  5.944444      0.83            14.1036   \n",
      "4         8.755556                  6.977778      0.83            11.0446   \n",
      "\n",
      "   Wind Bearing (degrees)  Visibility (km)  Pressure (millibars)  \n",
      "0                   251.0          15.8263               1015.13  \n",
      "1                   259.0          15.8263               1015.63  \n",
      "2                   204.0          14.9569               1015.94  \n",
      "3                   269.0          15.8263               1016.41  \n",
      "4                   259.0          15.8263               1016.51  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split # class to split data \n",
    "\n",
    "data_copy=data.copy()\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "Y =data[\"Precip Type\"]\n",
    "X=data.drop([\"Precip Type\"],axis=1)\n",
    "print(X.head())\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76748, 1)\n",
      "(19188, 1)\n",
      "(76748,)\n",
      "(19188,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scale = MinMaxScaler()\n",
    " # reshape because of minmax take column and scale\n",
    "scale.fit(X_train['Temperature (C)'].values.reshape(-1,1))\n",
    "X_train_temp = scale.transform(X_train['Temperature (C)'].values.reshape(-1,1))\n",
    "X_test_temp = scale.transform(X_test['Temperature (C)'].values.reshape(-1,1))\n",
    "print(X_train_temp.shape)\n",
    "print(X_test_temp.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76748, 1)\n",
      "(19188, 1)\n",
      "(76748,)\n",
      "(19188,)\n"
     ]
    }
   ],
   "source": [
    "scale = MinMaxScaler()\n",
    " # reshape because of minmax take column and scale\n",
    "scale.fit(X_train['Apparent Temperature (C)'].values.reshape(-1,1))\n",
    "X_train_atemp = scale.transform(X_train['Apparent Temperature (C)'].values.reshape(-1,1))\n",
    "X_test_atemp = scale.transform(X_test['Apparent Temperature (C)'].values.reshape(-1,1))\n",
    "print(X_train_atemp.shape)\n",
    "print(X_test_atemp.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76748, 1)\n",
      "(19188, 1)\n",
      "(76748,)\n",
      "(19188,)\n"
     ]
    }
   ],
   "source": [
    "scale = MinMaxScaler()\n",
    " # reshape because of minmax take column and scale\n",
    "scale.fit(X_train['Humidity'].values.reshape(-1,1))\n",
    "X_train_humid = scale.transform(X_train['Humidity'].values.reshape(-1,1))\n",
    "X_test_humid = scale.transform(X_test['Humidity'].values.reshape(-1,1))\n",
    "print(X_train_humid.shape)\n",
    "print(X_test_humid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76748, 1)\n",
      "(19188, 1)\n",
      "(76748,)\n",
      "(19188,)\n"
     ]
    }
   ],
   "source": [
    "scale = MinMaxScaler()\n",
    " # reshape because of minmax take column and scale\n",
    "scale.fit(X_train['Wind Speed (km/h)'].values.reshape(-1,1))\n",
    "X_train_wind = scale.transform(X_train['Wind Speed (km/h)'].values.reshape(-1,1))\n",
    "X_test_wind = scale.transform(X_test['Wind Speed (km/h)'].values.reshape(-1,1))\n",
    "print(X_train_wind.shape)\n",
    "print(X_test_wind.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76748, 1)\n",
      "(19188, 1)\n",
      "(76748,)\n",
      "(19188,)\n"
     ]
    }
   ],
   "source": [
    "scale = MinMaxScaler()\n",
    " # reshape because of minmax take column and scale\n",
    "scale.fit(X_train['Wind Bearing (degrees)'].values.reshape(-1,1))\n",
    "X_train_bwind = scale.transform(X_train['Wind Bearing (degrees)'].values.reshape(-1,1))\n",
    "X_test_bwind = scale.transform(X_test['Wind Bearing (degrees)'].values.reshape(-1,1))\n",
    "print(X_train_bwind.shape)\n",
    "print(X_test_bwind.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76748, 1)\n",
      "(19188, 1)\n",
      "(76748,)\n",
      "(19188,)\n"
     ]
    }
   ],
   "source": [
    "scale = MinMaxScaler()\n",
    " # reshape because of minmax take column and scale\n",
    "scale.fit(X_train['Visibility (km)'].values.reshape(-1,1))\n",
    "X_train_visi = scale.transform(X_train['Visibility (km)'].values.reshape(-1,1))\n",
    "X_test_visi = scale.transform(X_test['Visibility (km)'].values.reshape(-1,1))\n",
    "print(X_train_visi.shape)\n",
    "print(X_test_visi.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76748, 1)\n",
      "(19188, 1)\n",
      "(76748,)\n",
      "(19188,)\n"
     ]
    }
   ],
   "source": [
    "scale = MinMaxScaler()\n",
    " # reshape because of minmax take column and scale\n",
    "scale.fit(X_train['Pressure (millibars)'].values.reshape(-1,1))\n",
    "X_train_pres = scale.transform(X_train['Pressure (millibars)'].values.reshape(-1,1))\n",
    "X_test_pres = scale.transform(X_test['Pressure (millibars)'].values.reshape(-1,1))\n",
    "print(X_train_pres.shape)\n",
    "print(X_test_pres.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76748, 7)\n",
      "(19188, 7)\n",
      "(76748,)\n",
      "(19188,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SOUMEN MONDAL\\AppData\\Local\\Temp\\ipykernel_21380\\283478832.py:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train= train.astype(np.float)\n",
      "C:\\Users\\SOUMEN MONDAL\\AppData\\Local\\Temp\\ipykernel_21380\\283478832.py:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test= test.astype(np.float)\n",
      "C:\\Users\\SOUMEN MONDAL\\AppData\\Local\\Temp\\ipykernel_21380\\283478832.py:12: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train=y_train.astype(np.float)\n",
      "C:\\Users\\SOUMEN MONDAL\\AppData\\Local\\Temp\\ipykernel_21380\\283478832.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test=y_test.astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "import scipy.sparse as sp\n",
    "\n",
    "train = hstack((sp.csr_matrix(X_train_temp),X_train_atemp,X_train_humid,X_train_wind,X_train_bwind,X_train_visi,X_train_pres)).tocsr()\n",
    "test = hstack((sp.csr_matrix(X_test_temp),X_test_atemp,X_test_humid,X_test_wind,X_test_bwind,X_test_visi,X_test_pres)).tocsr()\n",
    "\n",
    "\n",
    "train= train.astype(np.float)\n",
    "test= test.astype(np.float)\n",
    "train=train.toarray()\n",
    "test=test.toarray()\n",
    "y_train=y_train.astype(np.float)\n",
    "y_test=y_test.astype(np.float)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    Dense(16,input_shape=(7,),activation='relu'),\n",
    "    Dense(32,activation='relu',use_bias=True),\n",
    "    Dense(2,activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2399/2399 - 3s - loss: 0.0940 - accuracy: 0.9656 - 3s/epoch - 1ms/step\n",
      "Epoch 2/100\n",
      "2399/2399 - 2s - loss: 0.0326 - accuracy: 0.9867 - 2s/epoch - 917us/step\n",
      "Epoch 3/100\n",
      "2399/2399 - 2s - loss: 0.0270 - accuracy: 0.9882 - 2s/epoch - 915us/step\n",
      "Epoch 4/100\n",
      "2399/2399 - 2s - loss: 0.0254 - accuracy: 0.9888 - 2s/epoch - 925us/step\n",
      "Epoch 5/100\n",
      "2399/2399 - 2s - loss: 0.0237 - accuracy: 0.9894 - 2s/epoch - 913us/step\n",
      "Epoch 6/100\n",
      "2399/2399 - 2s - loss: 0.0217 - accuracy: 0.9901 - 2s/epoch - 903us/step\n",
      "Epoch 7/100\n",
      "2399/2399 - 2s - loss: 0.0218 - accuracy: 0.9899 - 2s/epoch - 904us/step\n",
      "Epoch 8/100\n",
      "2399/2399 - 2s - loss: 0.0206 - accuracy: 0.9903 - 2s/epoch - 927us/step\n",
      "Epoch 9/100\n",
      "2399/2399 - 2s - loss: 0.0196 - accuracy: 0.9908 - 2s/epoch - 918us/step\n",
      "Epoch 10/100\n",
      "2399/2399 - 2s - loss: 0.0201 - accuracy: 0.9906 - 2s/epoch - 912us/step\n",
      "Epoch 11/100\n",
      "2399/2399 - 2s - loss: 0.0197 - accuracy: 0.9908 - 2s/epoch - 904us/step\n",
      "Epoch 12/100\n",
      "2399/2399 - 2s - loss: 0.0189 - accuracy: 0.9911 - 2s/epoch - 908us/step\n",
      "Epoch 13/100\n",
      "2399/2399 - 2s - loss: 0.0193 - accuracy: 0.9909 - 2s/epoch - 911us/step\n",
      "Epoch 14/100\n",
      "2399/2399 - 2s - loss: 0.0202 - accuracy: 0.9904 - 2s/epoch - 923us/step\n",
      "Epoch 15/100\n",
      "2399/2399 - 2s - loss: 0.0188 - accuracy: 0.9911 - 2s/epoch - 914us/step\n",
      "Epoch 16/100\n",
      "2399/2399 - 2s - loss: 0.0192 - accuracy: 0.9908 - 2s/epoch - 914us/step\n",
      "Epoch 17/100\n",
      "2399/2399 - 2s - loss: 0.0180 - accuracy: 0.9914 - 2s/epoch - 920us/step\n",
      "Epoch 18/100\n",
      "2399/2399 - 2s - loss: 0.0195 - accuracy: 0.9907 - 2s/epoch - 915us/step\n",
      "Epoch 19/100\n",
      "2399/2399 - 2s - loss: 0.0186 - accuracy: 0.9912 - 2s/epoch - 907us/step\n",
      "Epoch 20/100\n",
      "2399/2399 - 2s - loss: 0.0183 - accuracy: 0.9914 - 2s/epoch - 894us/step\n",
      "Epoch 21/100\n",
      "2399/2399 - 2s - loss: 0.0184 - accuracy: 0.9911 - 2s/epoch - 907us/step\n",
      "Epoch 22/100\n",
      "2399/2399 - 2s - loss: 0.0176 - accuracy: 0.9914 - 2s/epoch - 956us/step\n",
      "Epoch 23/100\n",
      "2399/2399 - 2s - loss: 0.0187 - accuracy: 0.9910 - 2s/epoch - 914us/step\n",
      "Epoch 24/100\n",
      "2399/2399 - 2s - loss: 0.0181 - accuracy: 0.9915 - 2s/epoch - 910us/step\n",
      "Epoch 25/100\n",
      "2399/2399 - 2s - loss: 0.0176 - accuracy: 0.9917 - 2s/epoch - 926us/step\n",
      "Epoch 26/100\n",
      "2399/2399 - 2s - loss: 0.0180 - accuracy: 0.9914 - 2s/epoch - 901us/step\n",
      "Epoch 27/100\n",
      "2399/2399 - 2s - loss: 0.0186 - accuracy: 0.9908 - 2s/epoch - 914us/step\n",
      "Epoch 28/100\n",
      "2399/2399 - 2s - loss: 0.0184 - accuracy: 0.9913 - 2s/epoch - 955us/step\n",
      "Epoch 29/100\n",
      "2399/2399 - 2s - loss: 0.0183 - accuracy: 0.9912 - 2s/epoch - 952us/step\n",
      "Epoch 30/100\n",
      "2399/2399 - 2s - loss: 0.0174 - accuracy: 0.9915 - 2s/epoch - 995us/step\n",
      "Epoch 31/100\n",
      "2399/2399 - 2s - loss: 0.0177 - accuracy: 0.9916 - 2s/epoch - 962us/step\n",
      "Epoch 32/100\n",
      "2399/2399 - 2s - loss: 0.0170 - accuracy: 0.9917 - 2s/epoch - 915us/step\n",
      "Epoch 33/100\n",
      "2399/2399 - 2s - loss: 0.0174 - accuracy: 0.9918 - 2s/epoch - 918us/step\n",
      "Epoch 34/100\n",
      "2399/2399 - 2s - loss: 0.0172 - accuracy: 0.9914 - 2s/epoch - 919us/step\n",
      "Epoch 35/100\n",
      "2399/2399 - 2s - loss: 0.0171 - accuracy: 0.9919 - 2s/epoch - 913us/step\n",
      "Epoch 36/100\n",
      "2399/2399 - 2s - loss: 0.0169 - accuracy: 0.9920 - 2s/epoch - 890us/step\n",
      "Epoch 37/100\n",
      "2399/2399 - 2s - loss: 0.0169 - accuracy: 0.9920 - 2s/epoch - 894us/step\n",
      "Epoch 38/100\n",
      "2399/2399 - 2s - loss: 0.0167 - accuracy: 0.9918 - 2s/epoch - 922us/step\n",
      "Epoch 39/100\n",
      "2399/2399 - 2s - loss: 0.0172 - accuracy: 0.9915 - 2s/epoch - 912us/step\n",
      "Epoch 40/100\n",
      "2399/2399 - 2s - loss: 0.0170 - accuracy: 0.9918 - 2s/epoch - 916us/step\n",
      "Epoch 41/100\n",
      "2399/2399 - 2s - loss: 0.0170 - accuracy: 0.9917 - 2s/epoch - 910us/step\n",
      "Epoch 42/100\n",
      "2399/2399 - 2s - loss: 0.0173 - accuracy: 0.9914 - 2s/epoch - 919us/step\n",
      "Epoch 43/100\n",
      "2399/2399 - 2s - loss: 0.0168 - accuracy: 0.9922 - 2s/epoch - 914us/step\n",
      "Epoch 44/100\n",
      "2399/2399 - 2s - loss: 0.0163 - accuracy: 0.9923 - 2s/epoch - 916us/step\n",
      "Epoch 45/100\n",
      "2399/2399 - 2s - loss: 0.0167 - accuracy: 0.9921 - 2s/epoch - 922us/step\n",
      "Epoch 46/100\n",
      "2399/2399 - 2s - loss: 0.0171 - accuracy: 0.9918 - 2s/epoch - 904us/step\n",
      "Epoch 47/100\n",
      "2399/2399 - 2s - loss: 0.0161 - accuracy: 0.9921 - 2s/epoch - 923us/step\n",
      "Epoch 48/100\n",
      "2399/2399 - 2s - loss: 0.0166 - accuracy: 0.9921 - 2s/epoch - 912us/step\n",
      "Epoch 49/100\n",
      "2399/2399 - 2s - loss: 0.0169 - accuracy: 0.9920 - 2s/epoch - 895us/step\n",
      "Epoch 50/100\n",
      "2399/2399 - 2s - loss: 0.0164 - accuracy: 0.9923 - 2s/epoch - 900us/step\n",
      "Epoch 51/100\n",
      "2399/2399 - 2s - loss: 0.0164 - accuracy: 0.9925 - 2s/epoch - 925us/step\n",
      "Epoch 52/100\n",
      "2399/2399 - 2s - loss: 0.0161 - accuracy: 0.9925 - 2s/epoch - 907us/step\n",
      "Epoch 53/100\n",
      "2399/2399 - 2s - loss: 0.0162 - accuracy: 0.9924 - 2s/epoch - 898us/step\n",
      "Epoch 54/100\n",
      "2399/2399 - 2s - loss: 0.0165 - accuracy: 0.9920 - 2s/epoch - 903us/step\n",
      "Epoch 55/100\n",
      "2399/2399 - 2s - loss: 0.0172 - accuracy: 0.9918 - 2s/epoch - 902us/step\n",
      "Epoch 56/100\n",
      "2399/2399 - 2s - loss: 0.0163 - accuracy: 0.9922 - 2s/epoch - 901us/step\n",
      "Epoch 57/100\n",
      "2399/2399 - 2s - loss: 0.0160 - accuracy: 0.9921 - 2s/epoch - 914us/step\n",
      "Epoch 58/100\n",
      "2399/2399 - 2s - loss: 0.0155 - accuracy: 0.9926 - 2s/epoch - 919us/step\n",
      "Epoch 59/100\n",
      "2399/2399 - 2s - loss: 0.0168 - accuracy: 0.9919 - 2s/epoch - 916us/step\n",
      "Epoch 60/100\n",
      "2399/2399 - 2s - loss: 0.0161 - accuracy: 0.9923 - 2s/epoch - 911us/step\n",
      "Epoch 61/100\n",
      "2399/2399 - 2s - loss: 0.0154 - accuracy: 0.9924 - 2s/epoch - 904us/step\n",
      "Epoch 62/100\n",
      "2399/2399 - 2s - loss: 0.0162 - accuracy: 0.9922 - 2s/epoch - 910us/step\n",
      "Epoch 63/100\n",
      "2399/2399 - 2s - loss: 0.0158 - accuracy: 0.9925 - 2s/epoch - 914us/step\n",
      "Epoch 64/100\n",
      "2399/2399 - 2s - loss: 0.0159 - accuracy: 0.9922 - 2s/epoch - 892us/step\n",
      "Epoch 65/100\n",
      "2399/2399 - 2s - loss: 0.0152 - accuracy: 0.9929 - 2s/epoch - 923us/step\n",
      "Epoch 66/100\n",
      "2399/2399 - 2s - loss: 0.0158 - accuracy: 0.9923 - 2s/epoch - 918us/step\n",
      "Epoch 67/100\n",
      "2399/2399 - 2s - loss: 0.0157 - accuracy: 0.9925 - 2s/epoch - 917us/step\n",
      "Epoch 68/100\n",
      "2399/2399 - 2s - loss: 0.0158 - accuracy: 0.9924 - 2s/epoch - 903us/step\n",
      "Epoch 69/100\n",
      "2399/2399 - 2s - loss: 0.0161 - accuracy: 0.9921 - 2s/epoch - 909us/step\n",
      "Epoch 70/100\n",
      "2399/2399 - 2s - loss: 0.0162 - accuracy: 0.9924 - 2s/epoch - 912us/step\n",
      "Epoch 71/100\n",
      "2399/2399 - 2s - loss: 0.0153 - accuracy: 0.9929 - 2s/epoch - 920us/step\n",
      "Epoch 72/100\n",
      "2399/2399 - 2s - loss: 0.0155 - accuracy: 0.9923 - 2s/epoch - 902us/step\n",
      "Epoch 73/100\n",
      "2399/2399 - 2s - loss: 0.0158 - accuracy: 0.9922 - 2s/epoch - 899us/step\n",
      "Epoch 74/100\n",
      "2399/2399 - 2s - loss: 0.0150 - accuracy: 0.9929 - 2s/epoch - 900us/step\n",
      "Epoch 75/100\n",
      "2399/2399 - 2s - loss: 0.0151 - accuracy: 0.9925 - 2s/epoch - 920us/step\n",
      "Epoch 76/100\n",
      "2399/2399 - 2s - loss: 0.0149 - accuracy: 0.9929 - 2s/epoch - 909us/step\n",
      "Epoch 77/100\n",
      "2399/2399 - 2s - loss: 0.0150 - accuracy: 0.9925 - 2s/epoch - 906us/step\n",
      "Epoch 78/100\n",
      "2399/2399 - 2s - loss: 0.0148 - accuracy: 0.9930 - 2s/epoch - 909us/step\n",
      "Epoch 79/100\n",
      "2399/2399 - 2s - loss: 0.0155 - accuracy: 0.9926 - 2s/epoch - 899us/step\n",
      "Epoch 80/100\n",
      "2399/2399 - 2s - loss: 0.0146 - accuracy: 0.9928 - 2s/epoch - 918us/step\n",
      "Epoch 81/100\n",
      "2399/2399 - 2s - loss: 0.0154 - accuracy: 0.9926 - 2s/epoch - 904us/step\n",
      "Epoch 82/100\n",
      "2399/2399 - 2s - loss: 0.0147 - accuracy: 0.9929 - 2s/epoch - 915us/step\n",
      "Epoch 83/100\n",
      "2399/2399 - 2s - loss: 0.0152 - accuracy: 0.9925 - 2s/epoch - 914us/step\n",
      "Epoch 84/100\n",
      "2399/2399 - 2s - loss: 0.0148 - accuracy: 0.9928 - 2s/epoch - 923us/step\n",
      "Epoch 85/100\n",
      "2399/2399 - 2s - loss: 0.0148 - accuracy: 0.9928 - 2s/epoch - 904us/step\n",
      "Epoch 86/100\n",
      "2399/2399 - 2s - loss: 0.0156 - accuracy: 0.9923 - 2s/epoch - 914us/step\n",
      "Epoch 87/100\n",
      "2399/2399 - 2s - loss: 0.0148 - accuracy: 0.9928 - 2s/epoch - 919us/step\n",
      "Epoch 88/100\n",
      "2399/2399 - 2s - loss: 0.0147 - accuracy: 0.9929 - 2s/epoch - 928us/step\n",
      "Epoch 89/100\n",
      "2399/2399 - 2s - loss: 0.0150 - accuracy: 0.9927 - 2s/epoch - 918us/step\n",
      "Epoch 90/100\n",
      "2399/2399 - 2s - loss: 0.0152 - accuracy: 0.9928 - 2s/epoch - 923us/step\n",
      "Epoch 91/100\n",
      "2399/2399 - 2s - loss: 0.0147 - accuracy: 0.9929 - 2s/epoch - 908us/step\n",
      "Epoch 92/100\n",
      "2399/2399 - 2s - loss: 0.0148 - accuracy: 0.9928 - 2s/epoch - 907us/step\n",
      "Epoch 93/100\n",
      "2399/2399 - 2s - loss: 0.0151 - accuracy: 0.9928 - 2s/epoch - 919us/step\n",
      "Epoch 94/100\n",
      "2399/2399 - 2s - loss: 0.0148 - accuracy: 0.9929 - 2s/epoch - 915us/step\n",
      "Epoch 95/100\n",
      "2399/2399 - 2s - loss: 0.0150 - accuracy: 0.9926 - 2s/epoch - 895us/step\n",
      "Epoch 96/100\n",
      "2399/2399 - 2s - loss: 0.0147 - accuracy: 0.9929 - 2s/epoch - 920us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "2399/2399 - 2s - loss: 0.0141 - accuracy: 0.9933 - 2s/epoch - 902us/step\n",
      "Epoch 98/100\n",
      "2399/2399 - 2s - loss: 0.0148 - accuracy: 0.9926 - 2s/epoch - 900us/step\n",
      "Epoch 99/100\n",
      "2399/2399 - 2s - loss: 0.0146 - accuracy: 0.9928 - 2s/epoch - 907us/step\n",
      "Epoch 100/100\n",
      "2399/2399 - 2s - loss: 0.0149 - accuracy: 0.9930 - 2s/epoch - 904us/step\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x=train,y=y_train,epochs=100,shuffle='True',verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1919/1919 [==============================] - 2s 906us/step - loss: 1690.2657 - accuracy: 0.2895\n",
      "test loss, test acc: [1690.2657470703125, 0.2895038425922394]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, batch_size=10)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 885us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "modeld = Sequential()\n",
    "modeld.add(Dropout(0.2, input_shape=(7,)))\n",
    "modeld.add(Dense(16, activation='relu'))\n",
    "modeld.add(Dropout(0.2))\n",
    "modeld.add(BatchNormalization())\n",
    "modeld.add(Dense(32, activation='relu'))\n",
    "modeld.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeld.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2399/2399 - 3s - loss: 0.2092 - accuracy: 0.9054 - 3s/epoch - 1ms/step\n",
      "Epoch 2/100\n",
      "2399/2399 - 3s - loss: 0.1285 - accuracy: 0.9409 - 3s/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "2399/2399 - 3s - loss: 0.1137 - accuracy: 0.9491 - 3s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "2399/2399 - 3s - loss: 0.1046 - accuracy: 0.9545 - 3s/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "2399/2399 - 3s - loss: 0.0981 - accuracy: 0.9582 - 3s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "2399/2399 - 3s - loss: 0.0924 - accuracy: 0.9618 - 3s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "2399/2399 - 3s - loss: 0.0853 - accuracy: 0.9655 - 3s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "2399/2399 - 3s - loss: 0.0817 - accuracy: 0.9675 - 3s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "2399/2399 - 3s - loss: 0.0800 - accuracy: 0.9685 - 3s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "2399/2399 - 3s - loss: 0.0788 - accuracy: 0.9681 - 3s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "2399/2399 - 3s - loss: 0.0765 - accuracy: 0.9694 - 3s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "2399/2399 - 3s - loss: 0.0767 - accuracy: 0.9692 - 3s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "2399/2399 - 3s - loss: 0.0749 - accuracy: 0.9701 - 3s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "2399/2399 - 3s - loss: 0.0751 - accuracy: 0.9700 - 3s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "2399/2399 - 3s - loss: 0.0735 - accuracy: 0.9711 - 3s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "2399/2399 - 3s - loss: 0.0733 - accuracy: 0.9717 - 3s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "2399/2399 - 3s - loss: 0.0738 - accuracy: 0.9711 - 3s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "2399/2399 - 3s - loss: 0.0732 - accuracy: 0.9708 - 3s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "2399/2399 - 3s - loss: 0.0735 - accuracy: 0.9706 - 3s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "2399/2399 - 3s - loss: 0.0717 - accuracy: 0.9712 - 3s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "2399/2399 - 3s - loss: 0.0739 - accuracy: 0.9702 - 3s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "2399/2399 - 3s - loss: 0.0733 - accuracy: 0.9703 - 3s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "2399/2399 - 3s - loss: 0.0740 - accuracy: 0.9700 - 3s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "2399/2399 - 3s - loss: 0.0721 - accuracy: 0.9704 - 3s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "2399/2399 - 3s - loss: 0.0723 - accuracy: 0.9705 - 3s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "2399/2399 - 3s - loss: 0.0722 - accuracy: 0.9706 - 3s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "2399/2399 - 3s - loss: 0.0728 - accuracy: 0.9703 - 3s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "2399/2399 - 3s - loss: 0.0699 - accuracy: 0.9719 - 3s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "2399/2399 - 3s - loss: 0.0737 - accuracy: 0.9702 - 3s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "2399/2399 - 3s - loss: 0.0708 - accuracy: 0.9714 - 3s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "2399/2399 - 3s - loss: 0.0720 - accuracy: 0.9704 - 3s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "2399/2399 - 3s - loss: 0.0718 - accuracy: 0.9716 - 3s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "2399/2399 - 3s - loss: 0.0713 - accuracy: 0.9713 - 3s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "2399/2399 - 3s - loss: 0.0714 - accuracy: 0.9710 - 3s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "2399/2399 - 3s - loss: 0.0684 - accuracy: 0.9724 - 3s/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "2399/2399 - 3s - loss: 0.0733 - accuracy: 0.9703 - 3s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "2399/2399 - 3s - loss: 0.0729 - accuracy: 0.9707 - 3s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "2399/2399 - 3s - loss: 0.0733 - accuracy: 0.9703 - 3s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "2399/2399 - 3s - loss: 0.0712 - accuracy: 0.9719 - 3s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "2399/2399 - 3s - loss: 0.0710 - accuracy: 0.9715 - 3s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "2399/2399 - 3s - loss: 0.0708 - accuracy: 0.9716 - 3s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "2399/2399 - 3s - loss: 0.0701 - accuracy: 0.9710 - 3s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "2399/2399 - 3s - loss: 0.0701 - accuracy: 0.9721 - 3s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "2399/2399 - 3s - loss: 0.0702 - accuracy: 0.9720 - 3s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "2399/2399 - 3s - loss: 0.0716 - accuracy: 0.9706 - 3s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "2399/2399 - 3s - loss: 0.0702 - accuracy: 0.9722 - 3s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "2399/2399 - 3s - loss: 0.0720 - accuracy: 0.9707 - 3s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "2399/2399 - 3s - loss: 0.0686 - accuracy: 0.9726 - 3s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "2399/2399 - 3s - loss: 0.0720 - accuracy: 0.9708 - 3s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "2399/2399 - 3s - loss: 0.0701 - accuracy: 0.9719 - 3s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "2399/2399 - 3s - loss: 0.0737 - accuracy: 0.9696 - 3s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "2399/2399 - 3s - loss: 0.0695 - accuracy: 0.9716 - 3s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "2399/2399 - 3s - loss: 0.0717 - accuracy: 0.9707 - 3s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "2399/2399 - 3s - loss: 0.0694 - accuracy: 0.9719 - 3s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "2399/2399 - 3s - loss: 0.0699 - accuracy: 0.9720 - 3s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "2399/2399 - 3s - loss: 0.0710 - accuracy: 0.9713 - 3s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "2399/2399 - 3s - loss: 0.0682 - accuracy: 0.9723 - 3s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "2399/2399 - 3s - loss: 0.0707 - accuracy: 0.9715 - 3s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "2399/2399 - 3s - loss: 0.0711 - accuracy: 0.9712 - 3s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "2399/2399 - 3s - loss: 0.0700 - accuracy: 0.9714 - 3s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "2399/2399 - 3s - loss: 0.0711 - accuracy: 0.9706 - 3s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "2399/2399 - 3s - loss: 0.0712 - accuracy: 0.9713 - 3s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "2399/2399 - 3s - loss: 0.0701 - accuracy: 0.9714 - 3s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "2399/2399 - 3s - loss: 0.0713 - accuracy: 0.9712 - 3s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "2399/2399 - 3s - loss: 0.0705 - accuracy: 0.9715 - 3s/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "2399/2399 - 3s - loss: 0.0693 - accuracy: 0.9720 - 3s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "2399/2399 - 3s - loss: 0.0693 - accuracy: 0.9723 - 3s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "2399/2399 - 3s - loss: 0.0680 - accuracy: 0.9729 - 3s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "2399/2399 - 3s - loss: 0.0701 - accuracy: 0.9720 - 3s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "2399/2399 - 3s - loss: 0.0709 - accuracy: 0.9714 - 3s/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "2399/2399 - 3s - loss: 0.0687 - accuracy: 0.9722 - 3s/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "2399/2399 - 3s - loss: 0.0695 - accuracy: 0.9725 - 3s/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "2399/2399 - 3s - loss: 0.0693 - accuracy: 0.9717 - 3s/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "2399/2399 - 3s - loss: 0.0700 - accuracy: 0.9715 - 3s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "2399/2399 - 3s - loss: 0.0699 - accuracy: 0.9721 - 3s/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "2399/2399 - 3s - loss: 0.0721 - accuracy: 0.9711 - 3s/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "2399/2399 - 3s - loss: 0.0692 - accuracy: 0.9718 - 3s/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "2399/2399 - 3s - loss: 0.0696 - accuracy: 0.9715 - 3s/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "2399/2399 - 3s - loss: 0.0691 - accuracy: 0.9725 - 3s/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "2399/2399 - 3s - loss: 0.0681 - accuracy: 0.9725 - 3s/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "2399/2399 - 3s - loss: 0.0701 - accuracy: 0.9715 - 3s/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "2399/2399 - 3s - loss: 0.0692 - accuracy: 0.9715 - 3s/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "2399/2399 - 3s - loss: 0.0701 - accuracy: 0.9709 - 3s/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "2399/2399 - 3s - loss: 0.0678 - accuracy: 0.9724 - 3s/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "2399/2399 - 3s - loss: 0.0678 - accuracy: 0.9724 - 3s/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "2399/2399 - 3s - loss: 0.0688 - accuracy: 0.9722 - 3s/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "2399/2399 - 3s - loss: 0.0689 - accuracy: 0.9723 - 3s/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "2399/2399 - 3s - loss: 0.0689 - accuracy: 0.9721 - 3s/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "2399/2399 - 3s - loss: 0.0691 - accuracy: 0.9719 - 3s/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "2399/2399 - 3s - loss: 0.0700 - accuracy: 0.9711 - 3s/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "2399/2399 - 3s - loss: 0.0678 - accuracy: 0.9729 - 3s/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "2399/2399 - 3s - loss: 0.0690 - accuracy: 0.9719 - 3s/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "2399/2399 - 3s - loss: 0.0707 - accuracy: 0.9717 - 3s/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "2399/2399 - 3s - loss: 0.0698 - accuracy: 0.9720 - 3s/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "2399/2399 - 3s - loss: 0.0688 - accuracy: 0.9716 - 3s/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "2399/2399 - 3s - loss: 0.0685 - accuracy: 0.9726 - 3s/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "2399/2399 - 3s - loss: 0.0687 - accuracy: 0.9726 - 3s/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "2399/2399 - 3s - loss: 0.0681 - accuracy: 0.9733 - 3s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "2399/2399 - 3s - loss: 0.0683 - accuracy: 0.9725 - 3s/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "2399/2399 - 3s - loss: 0.0685 - accuracy: 0.9726 - 3s/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "history=modeld.fit(x=train,y=y_train,epochs=100,shuffle='True',verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1919/1919 [==============================] - 2s 953us/step - loss: 119.3792 - accuracy: 0.8843\n",
      "test loss, test acc: [119.37915802001953, 0.8842505812644958]\n"
     ]
    }
   ],
   "source": [
    "resultsd = modeld.evaluate(X_test, y_test, batch_size=10)\n",
    "print('test loss, test acc:', resultsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"waethermodel.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "lmodel = load_model(\"waethermodel.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.730761   -0.06708974 -1.0884684   1.5582656   1.5352736   1.3437324\n",
      "  -0.94584066  1.6425061   0.6081863   1.7335769  -1.1931766  -1.3896786\n",
      "  -1.2133408   1.4653109   0.3219083  -0.26120758]\n",
      " [-0.17019688 -0.43922848 -0.02223482  1.1658286   0.47659177 -0.12259776\n",
      "  -0.499392    0.70873314  0.387362    0.31233713 -0.6181637  -1.0882156\n",
      "   0.591553    1.1206615   0.623274   -0.2773401 ]\n",
      " [ 0.15715732 -0.22290614 -0.10245889  0.29377842 -0.31602132 -0.2004094\n",
      "   0.45356017 -0.26721892 -0.19687568 -0.11439338 -0.16845958  0.2523748\n",
      "  -0.15554006  0.27650142  0.01363937 -0.40421113]\n",
      " [-1.5497932  -0.45355973  0.04117442  0.0534535   0.2552662  -0.2991549\n",
      "  -1.3520112   0.44541124 -0.341486    0.39467418  0.00814658  0.31540537\n",
      "  -2.7208707   0.21403031 -0.01573161 -0.35130006]\n",
      " [ 0.5121022  -0.42751902  0.7629803   0.17220815  0.36422753 -0.39665303\n",
      "  -0.22801292  0.0283776   0.1731622  -0.3226522   0.14106739 -0.0035543\n",
      "  -0.07693499 -0.2859367  -0.05513839  0.2061286 ]\n",
      " [-0.1470133  -0.29386365 -0.5997139   0.00518529  0.15583569  0.35966465\n",
      "   0.05663593 -0.09459047  0.75266904 -0.0380631   0.23354526  0.06326337\n",
      "   0.01954659  0.13682772  0.52042043 -0.36207673]\n",
      " [-0.18193372 -0.2958001  -0.5270826  -0.52312165 -0.01696749  0.10599031\n",
      "   0.23338422 -0.00739574 -0.35639086  0.117639    0.16067877  0.12235802\n",
      "   0.4791527  -0.45652652 -1.8183686  -0.07299307]]\n",
      "7\n",
      "\n",
      "############################################################\n",
      "[[-7.02636957e-01  7.24189818e-01 -3.88545208e-02  5.60026616e-02\n",
      "  -4.06739712e-01  3.01388919e-01 -2.68957913e-01 -9.58347976e-01\n",
      "   1.75911263e-01  8.97671655e-03 -1.96014255e-01  2.86507279e-01\n",
      "   5.60692608e-01 -2.32411385e-01  1.90249279e-01  1.40866622e-01\n",
      "   1.71316832e-01  6.86741322e-02  1.20382823e-01  6.35912597e-01\n",
      "  -7.11736828e-02  8.94312561e-01  4.04620707e-01 -2.93698221e-01\n",
      "  -1.34433997e+00 -1.50958702e-01 -8.63375887e-02 -7.97617316e-01\n",
      "  -1.90478697e-01  3.40195835e-01 -4.35341671e-02  9.38199759e-01]\n",
      " [-3.04667056e-02 -2.97197491e-01 -2.68509299e-01 -2.34149605e-01\n",
      "   1.26287967e-01 -3.35661709e-01  5.15506566e-02  4.44713235e-02\n",
      "   3.20477873e-01  2.23470777e-01 -4.44244742e-02  9.96305048e-02\n",
      "   2.61338353e-02 -1.06963888e-01 -5.64530492e-03 -2.11814374e-01\n",
      "   8.97410810e-02 -3.32949728e-01  7.70217180e-03  2.61229426e-01\n",
      "   3.48263294e-01 -1.87662795e-01 -1.85838774e-01  2.36403376e-01\n",
      "   2.10602552e-01 -3.35632205e-01 -2.21761629e-01 -2.73993611e-01\n",
      "  -8.18470716e-02 -3.21814269e-01  1.13242179e-01 -3.50511998e-01]\n",
      " [-3.05144221e-01  9.48475838e-01 -8.55405569e-01 -1.01859391e+00\n",
      "   1.55195743e-01  1.16536522e+00 -9.43111897e-01 -6.85481668e-01\n",
      "  -5.19692957e-01 -6.03281021e-01 -1.66188493e-01  1.01602972e+00\n",
      "   9.58040655e-01 -5.91793895e-01  9.00276721e-01 -1.03824079e+00\n",
      "   1.06416714e+00 -3.28946143e-01 -8.29309106e-01  9.42402065e-01\n",
      "  -3.04543614e-01  3.10937792e-01  1.01698756e+00 -2.07650080e-01\n",
      "  -8.54401946e-01 -2.19783396e-01 -7.56715178e-01 -8.90359208e-02\n",
      "  -5.49389780e-01  5.62763572e-01 -1.41368926e-01  9.02465343e-01]\n",
      " [-1.28457737e+00  8.80311728e-02  1.10671782e+00  1.14529061e+00\n",
      "  -1.06225476e-01 -3.05481374e-01  1.05134487e+00  6.37382090e-01\n",
      "  -1.68087602e+00  7.60886371e-01 -1.41649628e+00 -2.69309223e-01\n",
      "  -1.01799989e+00  1.13341999e+00 -6.15304232e-01  1.03555822e+00\n",
      "  -7.90443003e-01  7.36356676e-01  9.67221797e-01  7.27127865e-02\n",
      "  -8.60033453e-01 -7.24123895e-01 -1.35686028e+00 -1.71797231e-01\n",
      "   9.72905338e-01 -1.22205019e-01  7.48216927e-01  7.41904438e-01\n",
      "  -7.02342749e-01  4.07421768e-01  6.97297007e-02  2.04938531e-01]\n",
      " [-9.39663202e-02 -3.16015095e-01  5.09498715e-01  3.61481339e-01\n",
      "  -3.59971344e-01 -1.11719799e+00  5.71578026e-01  3.95542234e-01\n",
      "  -9.17996585e-01  4.51021403e-01 -7.82761052e-02 -7.66663253e-01\n",
      "  -2.76932597e-01  5.43915689e-01 -4.75484341e-01  7.08864212e-01\n",
      "  -2.80421615e-01  3.26205999e-01  5.22550046e-01  6.42805219e-01\n",
      "  -2.38510072e-01 -8.78443122e-01 -8.02024782e-01  2.71290153e-01\n",
      "   7.72362828e-01 -3.20875078e-01  7.94162095e-01  5.83329678e-01\n",
      "  -2.61756722e-02  7.22706676e-01 -1.52917758e-01  8.36955458e-02]\n",
      " [-1.65254623e-01  9.75431323e-01  3.19985151e-02  4.22135323e-01\n",
      "  -2.62054056e-01  2.42624849e-01  4.33455259e-01  2.64163733e-01\n",
      "  -2.94886976e-01  1.31451413e-01  3.08792174e-01 -1.55963078e-01\n",
      "  -2.67421871e-01  7.97195882e-02 -3.50568146e-01  6.88607916e-02\n",
      "   1.90961331e-01  5.78637272e-02  2.97514647e-01  3.41165125e-01\n",
      "  -2.98530310e-02  3.32226813e-01  2.51825333e-01 -3.32768828e-01\n",
      "   3.48245680e-01 -4.34578329e-01  1.97143957e-01  1.75397336e-01\n",
      "   3.99039477e-01 -2.99625266e-02 -2.39520222e-01 -6.51240647e-01]\n",
      " [ 5.03489226e-02 -1.19548643e+00  4.87643853e-03  2.31734738e-02\n",
      "   1.15507245e-01  3.38017315e-01  6.17728615e-03  1.22175872e-01\n",
      "  -4.40577529e-02 -2.69073516e-01  1.42682642e-01  5.00383615e-01\n",
      "  -1.08618118e-01  7.31002390e-02  3.59121680e-01  7.27452189e-02\n",
      "   6.25344962e-02 -3.18464302e-02  1.73321879e-03  7.40079522e-01\n",
      "   2.80677199e-01  2.17282191e-01  6.87508702e-01 -1.72969863e-01\n",
      "   1.68546110e-01  1.92542255e-01  5.93316332e-02 -1.43162021e-02\n",
      "   2.64403045e-01  4.58203584e-01 -4.52224135e-01 -3.55900884e-01]\n",
      " [-6.33434415e-01 -7.79959202e-01  1.16327357e+00  9.28640068e-01\n",
      "   1.92031443e-01 -1.86561716e+00  1.20170939e+00  7.81859815e-01\n",
      "  -3.33010435e-01  7.25405335e-01 -1.16918020e-01 -1.70361006e+00\n",
      "  -6.52820706e-01  1.12226939e+00 -4.03574884e-01  7.89211094e-01\n",
      "  -1.05357349e+00  5.40435374e-01  7.60718286e-01  3.11172962e-01\n",
      "  -5.21878541e-01 -1.10360086e+00 -8.39941680e-01 -3.19896907e-01\n",
      "   1.03737104e+00 -5.33238649e-01  1.35259676e+00  7.78920352e-01\n",
      "  -9.59688306e-01 -9.04210471e-03 -2.12395087e-01 -4.23314571e-01]\n",
      " [-2.82322377e-01  6.40839219e-01  2.45208114e-01  2.15592131e-01\n",
      "   1.22392163e-01  7.54339635e-01  2.39609212e-01  2.04212323e-01\n",
      "  -4.70194295e-02  3.29246700e-01 -1.21096693e-01  2.97890425e-01\n",
      "   3.74235697e-02  1.83321521e-01  1.40505582e-01 -9.39486921e-02\n",
      "   9.37633961e-02  2.62480259e-01 -1.89170633e-02  4.01229441e-01\n",
      "  -4.06092256e-01  4.44109768e-01  7.54836380e-01 -2.46220723e-01\n",
      "   2.77349114e-01  8.84506404e-02  9.22288969e-02  3.37041974e-01\n",
      "  -4.83252972e-01  3.46701711e-01  1.62487581e-01 -8.72485220e-01]\n",
      " [ 2.29083449e-01 -1.05047846e+00  6.60799503e-01  7.00798452e-01\n",
      "  -3.24552894e-01 -4.04757351e-01  4.65315849e-01  1.69687837e-01\n",
      "   5.96223533e-01  2.22236216e-01  4.19239432e-01 -4.79978949e-01\n",
      "  -5.39717197e-01  6.94225967e-01 -1.32703260e-01  7.09613085e-01\n",
      "  -1.96204513e-01  4.36637342e-01  5.11212587e-01 -5.70775419e-02\n",
      "   8.71895999e-02  2.06427038e-01  2.11252198e-01  1.78769976e-01\n",
      "   6.95252597e-01 -4.56319824e-02  4.92257684e-01  4.84620124e-01\n",
      "  -8.39192346e-02 -1.81587860e-01  5.79940453e-02 -2.42785835e+00]\n",
      " [ 3.05016071e-01  1.35959655e-01 -2.61613548e-01 -2.41200998e-01\n",
      "  -2.77735442e-02  1.10106342e-01 -1.90717623e-01  1.00480713e-01\n",
      "   2.90799141e-01 -4.43342537e-01  3.81881446e-01  1.86887339e-01\n",
      "   3.66155267e-01 -3.18828613e-01  3.96626323e-01 -3.24620873e-01\n",
      "   1.42846912e-01  3.66605781e-02 -2.76003301e-01 -5.80270290e-01\n",
      "   4.05845344e-01  2.67957717e-01  3.25872898e-01  5.22036441e-02\n",
      "  -4.55282867e-01  1.94724977e-01 -2.46695995e-01 -3.84624749e-01\n",
      "   8.75215754e-02 -8.12122524e-01 -2.87138462e-01  4.72115368e-01]\n",
      " [ 8.23334455e-01  1.31147906e-01 -2.93893695e-01 -8.24989319e-01\n",
      "  -1.43375620e-01  9.18586850e-01 -9.30258274e-01 -4.05818105e-01\n",
      "   6.12417817e-01 -7.58772731e-01  1.35207057e+00  8.04234564e-01\n",
      "   7.81883895e-01 -7.19514489e-01  8.34988773e-01 -6.67450309e-01\n",
      "   9.94140387e-01 -7.50150025e-01 -8.13594818e-01 -2.25006676e+00\n",
      "   5.70767045e-01  1.05111182e+00  9.28225100e-01  1.00520685e-01\n",
      "  -4.43842679e-01 -1.73315346e-01 -6.08636498e-01 -7.81033635e-01\n",
      "   7.28842735e-01 -3.00237846e+00 -1.60632148e-01 -7.41913557e-01]\n",
      " [ 9.60914075e-01 -1.30623460e-01 -1.66023445e+00 -7.67468095e-01\n",
      "  -2.99520850e-01 -1.03863500e-01 -8.23167861e-01 -3.21939051e-01\n",
      "  -1.32815504e+00 -8.19918871e-01 -7.64788628e-01  2.45374486e-01\n",
      "   9.50332284e-01 -5.62786877e-01  6.34308159e-01 -7.25140572e-01\n",
      "   8.06252360e-01 -4.08497155e-01 -5.33992112e-01  4.86551970e-01\n",
      "   8.69721293e-01  4.11073178e-01  3.45912367e-01 -2.79811054e-01\n",
      "  -2.61155516e-01 -3.14850241e-01 -6.03919327e-01 -1.39235234e+00\n",
      "   7.43849218e-01  1.90298498e+00 -2.98870176e-01  5.89563787e-01]\n",
      " [-1.26443076e+00  4.17896807e-01  8.73724341e-01  1.25623417e+00\n",
      "   3.55718695e-02 -1.23400621e-01  1.00647712e+00  1.21084654e+00\n",
      "  -5.03031276e-02  7.35379696e-01 -1.07761610e+00 -7.00801432e-01\n",
      "  -4.58867043e-01  8.73199046e-01 -1.04215264e+00  9.69879866e-01\n",
      "  -9.17208970e-01  9.04825568e-01  8.64195764e-01  5.87413371e-01\n",
      "  -1.15536571e+00 -7.79393971e-01 -8.80752504e-01 -2.64161974e-01\n",
      "   8.61768425e-01  4.16852720e-02  1.02969348e+00  1.14568388e+00\n",
      "  -1.11580288e+00  2.31653929e-01  6.30655736e-02 -6.38206124e-01]\n",
      " [-3.64532828e-01  4.09240067e-01 -7.76168764e-01 -7.91332424e-01\n",
      "   4.05284725e-02  8.03814054e-01 -7.36646712e-01 -5.06475210e-01\n",
      "   8.75102162e-01 -4.84073043e-01 -1.05217978e-01  6.94857717e-01\n",
      "   6.49354935e-01 -6.53790295e-01  9.80747879e-01 -7.03646421e-01\n",
      "   9.39575970e-01 -6.16660416e-01 -6.61966920e-01 -2.83294052e-01\n",
      "  -7.48422980e-01  9.39392805e-01 -6.60863698e-01  1.83403313e-01\n",
      "  -5.74493229e-01 -2.39168555e-01 -7.21685290e-01 -6.08590007e-01\n",
      "  -8.29210520e-01 -1.62188157e-01 -4.33574840e-02  3.34448725e-01]\n",
      " [ 2.02537864e-01 -1.99758857e-01  9.91562903e-02  2.46202916e-01\n",
      "  -9.44293439e-02  1.88155323e-01  1.09965086e-01  2.59760112e-01\n",
      "  -2.15651095e-01  1.89344794e-01  1.38464779e-01 -3.10210317e-01\n",
      "   1.29356354e-01 -1.24625623e-01 -1.88137203e-01  8.24891329e-02\n",
      "  -8.32915306e-03 -5.22307456e-02  3.04084927e-01 -4.40304875e-02\n",
      "   2.75904328e-01 -4.26656902e-02  1.77198917e-01  2.47240633e-01\n",
      "   2.59685427e-01 -3.34636867e-01 -9.17622447e-03  1.82257295e-02\n",
      "  -1.29241288e-01  6.99432790e-02 -7.50909448e-02  2.42073208e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_hidden_weights = model.layers[0].get_weights()[0]\n",
    "Hidden_output_weights = model.layers[1].get_weights()[0]\n",
    "print(Input_hidden_weights)\n",
    "print(len(Input_hidden_weights))\n",
    "print(\"\\n############################################################\")\n",
    "print(Hidden_output_weights)\n",
    "len(Hidden_output_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
